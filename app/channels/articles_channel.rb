class ArticlesChannel < ApplicationCable::Channel
  def subscribed
    # Stream name follows "resource_id" pattern (e.g., "post_123", "user_456")
    @stream_name = params[:stream_name]
    reject unless @stream_name

    # TODO: Add stream validation if needed (pattern check, ownership, etc.)
    stream_from @stream_name
  rescue StandardError => e
    handle_channel_error(e)
    reject
  end
  
  def build_draft_prompt(transcript, brainstorm_content, model_display_name)
    <<~PROMPT
      âš ï¸ ã€æ ¸å¿ƒä»»åŠ¡ã€‘
      ä½ ç°åœ¨æ˜¯ä½œè€…æœ¬äººï¼Œè¦å°†è‡ªå·±çš„åˆæ­¥æƒ³æ³•å’Œæ·±åº¦æ€è€ƒèåˆæˆä¸€ç¯‡å®Œæ•´æ–‡ç« ã€‚
      
      ğŸš« ã€ç»å¯¹ç¦æ­¢ã€‘ï¼ˆè¿åä»»ä½•ä¸€æ¡éƒ½ç®—å¤±è´¥ï¼‰
      1. ç¦æ­¢ç¬¬ä¸‰æ–¹è§†è§’ï¼šä¸èƒ½å‡ºç°"æœ‰äººè¯´"ã€"æ ¹æ®XX"ã€"XXæåˆ°"ã€"åˆ†æè®¤ä¸º"ç­‰æ—è§‚è€…è¡¨è¿°
      2. ç¦æ­¢ä»‹ç»æ€§è¯­æ°”ï¼šä¸èƒ½ç”¨"è¿™ä¸ªç³»ç»Ÿ"ã€"è¿™å¥—æ–¹æ³•"ç­‰ä»‹ç»å·²æœ‰äº‹ç‰©çš„å£å»
      3. ç¦æ­¢å¯è§æ‹¼æ¥ï¼šä¸èƒ½è®©è¯»è€…æ„Ÿè§‰æ˜¯ä¸¤æ®µå†…å®¹æ‹¼åœ¨ä¸€èµ·
      4. ç¦æ­¢å¼•ç”¨åŸæ–‡ï¼šä¸èƒ½ç›´æ¥å¼•ç”¨ä¸‹é¢ç´ æçš„åŸè¯ï¼Œè¦å½»åº•æ¶ˆåŒ–åé‡æ–°è¡¨è¾¾
      5. **ç¦æ­¢å†…å®¹æ‰©å±•**ï¼šä¸èƒ½æ·»åŠ ç´ æä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€æ¡ˆä¾‹ã€ç»†èŠ‚ï¼ˆè¿™æ˜¯æœ€ä¸¥é‡çš„è¿è§„ï¼ï¼‰
      6. **ç¦æ­¢è¯¦ç»†å±•å¼€**ï¼šå¦‚æœç´ æåªæ˜¯æåˆ°ï¼Œå°±ä¸è¦è¯¦ç»†æè¿°ï¼ˆå¦‚ï¼šç´ æè¯´"6ä¸ªæ¨¡å‹"ï¼Œä½ ä¸èƒ½å±•å¼€å†™æ¯ä¸ªæ¨¡å‹çš„å†…å®¹ï¼‰
      
      âœ… ã€å¿…é¡»åšåˆ°ã€‘
      1. çº¯ç¬¬ä¸€äººç§°ï¼š"æˆ‘æœ€è¿‘..."ã€"æˆ‘å‘ç°..."ã€"æˆ‘è¯•äº†..."ï¼ˆåƒæ—¥è®°æˆ–åšå®¢ï¼‰
      2. è‡ªç„¶æµç•…ï¼šåƒè‡ªå·±æ€è€ƒåä¸€æ°”å‘µæˆå†™å‡ºæ¥çš„ï¼Œä¸æ˜¯æ•´ç†ä»–äººè§‚ç‚¹
      3. ä¿æŒ #{model_display_name} é£æ ¼ï¼šç›´æ¥ã€æ·±åˆ»ã€æœ‰æ´è§ã€å£è¯­åŒ–ã€ä¸å¥—è¯
      4. é¢å‘è¯»è€…ï¼šåƒè·Ÿæœ‹å‹é¢å¯¹é¢èŠå¤©ï¼Œæœ‰äº’åŠ¨æ„Ÿï¼ˆå¦‚ï¼š"ä½ è¯•è¿‡å—ï¼Ÿ"ã€"å…³é”®æ˜¯..."ï¼‰
      5. **ä¸¥æ ¼æ§åˆ¶é•¿åº¦**ï¼šèåˆç»“æœåº”è¯¥åœ¨ï¼ˆç´ æ1å­—æ•° + ç´ æ2å­—æ•°ï¼‰Ã— 1.5 å€ä»¥å†…ï¼Œç»ä¸è¶…è¿‡
      6. **åªæ•´åˆå·²æœ‰ä¿¡æ¯**ï¼šç´ ææåˆ°ä»€ä¹ˆå°±å†™ä»€ä¹ˆï¼Œä¸æåˆ°çš„ä¸€å¾‹ä¸å†™ï¼Œä¸è„‘è¡¥ï¼Œä¸ä¸¾ä¾‹
      
      âš¡ ã€å…³é”®åŸåˆ™ï¼šèåˆ â‰  æ‰©å±•ã€‘
      - âœ… èåˆ = æŠŠä¸¤æ®µè¯ç”¨ç»Ÿä¸€å£å»é‡æ–°è¯´ä¸€éï¼ˆä¿¡æ¯æ€»é‡ä¸å˜ï¼‰
      - âŒ æ‰©å±• = åŸºäºä¸¤æ®µè¯åˆ›é€ æ–°å†…å®¹ï¼ˆä¸¥é‡è¿è§„ï¼ï¼‰
      - ä¸¾ä¾‹è¯´æ˜ï¼š
        - ç´ æè¯´"æä¾›äº†6ä¸ªæ¨¡å‹" â†’ èåˆï¼š"æˆ‘æäº†6ä¸ªæ¨¡å‹"ï¼ˆâœ… æ­£ç¡®ï¼‰
        - ç´ æè¯´"æä¾›äº†6ä¸ªæ¨¡å‹" â†’ æ‰©å±•ï¼š"ç¬¬ä¸€ä¸ªæ˜¯XXï¼Œç¬¬äºŒä¸ªæ˜¯XX..."ï¼ˆâŒ ä¸¥é‡è¿è§„ï¼ï¼‰
        - ç´ æè¯´"é’ˆå¯¹ä¸åŒåœºæ™¯" â†’ èåˆï¼š"æ¯ä¸ªé’ˆå¯¹ä¸åŒåœºæ™¯"ï¼ˆâœ… æ­£ç¡®ï¼‰
        - ç´ æè¯´"é’ˆå¯¹ä¸åŒåœºæ™¯" â†’ æ‰©å±•ï¼š"æ¯”å¦‚é€šå‹¤æ—¶ã€æ—©ä¸Šé†’æ¥æ—¶..."ï¼ˆâŒ ä¸¥é‡è¿è§„ï¼ï¼‰
      
      ğŸ“ ã€æ ¼å¼è¦æ±‚ - å¿…é¡»ä½¿ç”¨ Markdownã€‘
      ä½ **å¿…é¡»**ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼ŒåŒ…æ‹¬ï¼š
      - **æ ‡é¢˜ç»“æ„**ï¼šä½¿ç”¨ ## äºŒçº§æ ‡é¢˜ å’Œ ### ä¸‰çº§æ ‡é¢˜æ¥ç»„ç»‡å†…å®¹ï¼ˆä¸è¦ä½¿ç”¨ # ä¸€çº§æ ‡é¢˜ï¼‰
      - **é‡ç‚¹å¼ºè°ƒ**ï¼šç”¨ **åŠ ç²—** æ ‡è®°å…³é”®è¯å’Œé‡è¦è§‚ç‚¹
      - **åˆ—è¡¨**ï¼šç”¨ - æˆ–æ•°å­—åˆ—è¡¨æ¥å‘ˆç°è¦ç‚¹
      - **æ®µè½åˆ†éš”**ï¼šæ®µè½ä¹‹é—´ç©ºä¸€è¡Œ
      - **é€»è¾‘æ¸…æ™°**ï¼šç”¨æ ‡é¢˜å’Œåˆ—è¡¨è®©æ–‡ç« ç»“æ„ä¸€ç›®äº†ç„¶
      
      ç¤ºä¾‹æ ¼å¼ï¼š
      ```
      ## æˆ‘çš„å‘ç°
      
      æœ€è¿‘æˆ‘åœ¨æ€è€ƒä¸€ä¸ªé—®é¢˜...
      
      ### å…³é”®è¦ç‚¹
      
      - **ç¬¬ä¸€ç‚¹**ï¼šé‡è¦å†…å®¹
      - **ç¬¬äºŒç‚¹**ï¼šå¦ä¸€ä¸ªè¦ç‚¹
      
      ### å…·ä½“å®è·µ
      
      æˆ‘å°è¯•äº†ä»¥ä¸‹æ–¹æ³•ï¼š
      
      1. é¦–å…ˆåšäº†...
      2. ç„¶åå‘ç°...
      ```
      
      ğŸ“ ã€å†™ä½œæŒ‡å—ã€‘
      - è§’è‰²ï¼šä½ å°±æ˜¯ä½œè€…æœ¬äººï¼Œæ­£åœ¨å†™ä¸€ç¯‡ä¸ªäººåšå®¢/å…¬ä¼—å·æ–‡ç« 
      - ç´ æç”¨æ³•ï¼šä¸‹é¢çš„å†…å®¹æ˜¯ä½ çš„ç¬”è®°å’Œè‰ç¨¿ï¼Œç°åœ¨è¦æ•´ç†æˆæ­£å¼æ–‡ç« 
      - **å†…å®¹å–èˆ**ï¼šåªèƒ½åˆ å‡ã€é‡ç»„ã€æ¢è¯´æ³•ï¼Œç»ä¸èƒ½æ‰©å±•ã€ä¸¾ä¾‹ã€è¯¦è¿°
      - è¾“å‡ºè¦æ±‚ï¼šç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„æ–‡ç« æ­£æ–‡ï¼Œä¸è¦åŠ æ–‡ç« æ€»æ ‡é¢˜ã€è§£é‡Šæˆ–ä»»ä½•å¤šä½™å†…å®¹
      - **é•¿åº¦æ§åˆ¶**ï¼šå†™å®Œç«‹å³åœæ­¢ï¼Œä¸è¦ä¸ºäº†å‡‘å­—æ•°è€Œå•°å—¦
      
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      ã€ç´ æ1ï¼šåˆæ­¥æƒ³æ³•ã€‘
      #{transcript}
      
      ã€ç´ æ2ï¼šæ·±åº¦æ€è€ƒã€‘
      #{brainstorm_content}
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      
      ç°åœ¨ï¼Œä»¥ç¬¬ä¸€äººç§°ã€ä½¿ç”¨ Markdown æ ¼å¼å†™å‡ºèåˆåçš„å®Œæ•´æ–‡ç« ï¼ˆç›´æ¥å¼€å§‹ï¼Œä¸è¦å‰è¨€ï¼‰ï¼š
      
      âš ï¸ ã€æœ€ç»ˆæé†’ã€‘
      - åªæ•´åˆç´ æä¸­çš„ä¿¡æ¯ï¼Œä¸æ‰©å±•ï¼Œä¸è¯¦è¿°ï¼Œä¸ä¸¾ä¾‹
      - å­—æ•°æ§åˆ¶åœ¨ç´ ææ€»å­—æ•°çš„1.5å€ä»¥å†…
      - å†™å®Œç«‹å³åœæ­¢ï¼Œä¸è¦ä¸ºäº†è¾¾åˆ°æŸä¸ªå­—æ•°è€Œç»§ç»­
      - **å¿…é¡»ä½¿ç”¨ Markdown æ ¼å¼**ï¼šæ ‡é¢˜ã€åŠ ç²—ã€åˆ—è¡¨ç­‰
    PROMPT
  end
  
  # Generate drafts for all providers concurrently
  def generate_all_drafts(data)
    article_id = data['article_id']
    
    article = Article.find(article_id)
    
    # List of all available providers (5 models displayed)
    providers = ['grok', 'qwen', 'deepseek', 'gemini', 'zhipu']
    
    # Trigger draft generation for all providers concurrently
    providers.each do |provider|
      # Check if brainstorm exists for this provider
      brainstorm_content = article.send("brainstorm_#{provider}")
      
      # Skip if no brainstorm content
      next if brainstorm_content.blank?
      
      # Set draft status to pending
      article.set_draft_status(provider, 'pending')
      
      # Get model display name
      model_display_name = case provider
      when 'grok' then 'Grok'
      when 'qwen' then 'Qwen'
      when 'deepseek' then 'DeepSeek'
      when 'gemini' then 'Gemini'
      when 'zhipu' then 'æ™ºè°±'
      when 'doubao' then 'è±†åŒ…'
      else provider.capitalize
      end
      
      # Build draft prompt
      draft_prompt = build_draft_prompt(article.transcript, brainstorm_content, model_display_name)
      
      llm_config = get_llm_config(provider)
      llm_config_with_timeout = llm_config.merge(timeout: 240, max_tokens: 8000)
      
      LlmStreamJob.perform_later(
        stream_name: "#{@stream_name}_draft_#{provider}",
        prompt: draft_prompt,
        llm_config: llm_config_with_timeout,
        article_id: article.id,
        provider: "draft_#{provider}",
        streaming: false
      )
    end
    
    # Broadcast that draft generation started
    ActionCable.server.broadcast(
      @stream_name,
      {
        type: 'all-drafts-started',
        article_id: article.id
      }
    )
  end
  
  # Regenerate a single provider's draft
  def regenerate_draft(data)
    article_id = data['article_id']
    provider = data['provider']
    
    unless article_id && provider
      Rails.logger.error "Missing article_id or provider for draft regeneration"
      return
    end
    
    article = Article.find_by(id: article_id)
    unless article
      Rails.logger.error "Article not found: #{article_id}"
      return
    end
    
    # Check if brainstorm exists
    brainstorm_content = article.send("brainstorm_#{provider}")
    if brainstorm_content.blank?
      Rails.logger.error "No brainstorm content for provider: #{provider}"
      return
    end
    
    # Clear previous error and set to pending
    article.set_draft_status(provider, 'pending')
    
    # Get model display name
    model_display_name = case provider
    when 'grok' then 'Grok'
    when 'qwen' then 'Qwen'
    when 'deepseek' then 'DeepSeek'
    when 'gemini' then 'Gemini'
    when 'zhipu' then 'æ™ºè°±'
    when 'doubao' then 'è±†åŒ…'
    else provider.capitalize
    end
    
    # Build draft prompt
    draft_prompt = build_draft_prompt(article.transcript, brainstorm_content, model_display_name)
    
    llm_config = get_llm_config(provider)
    llm_config_with_timeout = llm_config.merge(timeout: 240, max_tokens: 8000)
    
    LlmStreamJob.perform_later(
      stream_name: "#{@stream_name}_draft_#{provider}",
      prompt: draft_prompt,
      llm_config: llm_config_with_timeout,
      article_id: article.id,
      provider: "draft_#{provider}",
      streaming: false
    )
    
    # Broadcast regeneration started
    ActionCable.server.broadcast(
      @stream_name,
      {
        type: 'draft-regeneration-started',
        provider: provider,
        article_id: article.id
      }
    )
  end

  def unsubscribed
    # Any cleanup needed when channel is unsubscribed
  rescue StandardError => e
    handle_channel_error(e)
  end

  # ğŸ“¨ CRITICAL: ALL broadcasts MUST have 'type' field (auto-routes to handleType method)
  #
  # EXAMPLE: Send new message
  # def send_message(data)
  #   message = Message.create!(content: data['content'])
  #
  #   ActionCable.server.broadcast(
  #     @stream_name,
  #     {
  #       type: 'new-message',  # REQUIRED: routes to handleNewMessage() in frontend
  #       id: message.id,
  #       content: message.content,
  #       user_name: message.user.name,
  #       created_at: message.created_at
  #     }
  #   )
  # end

  # EXAMPLE: Send status update
  # def update_status(data)
  #   ActionCable.server.broadcast(
  #     @stream_name,
  #     {
  #       type: 'status-update',  # Routes to handleStatusUpdate() in frontend
  #       status: data['status']
  #     }
  #   )
  # end
  # Generate response with ALL available LLM providers concurrently
  def generate_response(data)
    transcript = data['transcript']
    article_id = data['article_id']
    thinking_framework = data['thinking_framework'] || 'original'
    # Use blocking (non-streaming) mode by default to fix Markdown format issues
    streaming = data['streaming'] || false
    
    # Create or update article with transcript and thinking_framework
    article = if article_id.present?
                Article.find(article_id)
              else
                # Associate with current_user if authenticated
                article_attrs = { transcript: transcript, thinking_framework: thinking_framework }
                article_attrs[:user_id] = current_user.id if current_user
                Article.create!(article_attrs)
              end
    
    # List of all available providers (Doubao hidden)
    providers = ['grok', 'qwen', 'deepseek', 'gemini', 'zhipu']
    
    # Trigger jobs for all providers concurrently
    providers.each do |provider|
      llm_config = get_llm_config(provider)
      
      # Set pending status before triggering job
      article.set_brainstorm_status(provider, 'pending')
      
      LlmStreamJob.perform_later(
        stream_name: "#{@stream_name}_#{provider}",
        prompt: transcript,
        llm_config: llm_config,
        article_id: article.id,
        provider: provider,
        thinking_framework: thinking_framework,
        streaming: streaming
      )
    end
    
    # Broadcast article_id back to frontend
    ActionCable.server.broadcast(
      @stream_name,
      {
        type: 'article-created',
        article_id: article.id
      }
    )
  end
  
  # Regenerate a single provider's brainstorm
  def regenerate_provider(data)
    article_id = data['article_id']
    provider = data['provider']
    
    unless article_id && provider
      Rails.logger.error "Missing article_id or provider for regeneration"
      return
    end
    
    article = Article.find_by(id: article_id)
    unless article
      Rails.logger.error "Article not found: #{article_id}"
      return
    end
    
    # Clear previous error and set to pending
    article.set_brainstorm_status(provider, 'pending')
    
    # Get LLM config for provider
    llm_config = get_llm_config(provider)
    
    # Trigger job for this provider
    LlmStreamJob.perform_later(
      stream_name: "#{@stream_name}_#{provider}",
      prompt: article.transcript,
      llm_config: llm_config,
      article_id: article.id,
      provider: provider,
      thinking_framework: article.thinking_framework || 'original',
      streaming: data['streaming'] || false
    )
    
    # Broadcast regeneration started
    ActionCable.server.broadcast(
      @stream_name,
      {
        type: 'regeneration-started',
        provider: provider,
        article_id: article.id
      }
    )
  end
  
  # Generate draft by combining transcript + all brainstorm results
  def generate_draft(data)
    article_id = data['article_id']
    selected_model = data['selected_model']
    
    article = Article.find(article_id)
    article.update!(selected_model: selected_model)
    
    # æ ¹æ®é€‰ä¸­çš„æ¨¡å‹è·å–å¯¹åº”çš„è„‘çˆ†å†…å®¹
    selected_brainstorm = case selected_model.to_s
    when 'grok'
      article.brainstorm_grok
    when 'qwen'
      article.brainstorm_qwen
    when 'deepseek'
      article.brainstorm_deepseek
    when 'gemini'
      article.brainstorm_gemini
    when 'zhipu'
      article.brainstorm_zhipu
    when 'doubao'
      article.brainstorm_doubao
    else
      article.brainstorm_grok # é»˜è®¤ä½¿ç”¨ Grok
    end
    
    # è·å–æ¨¡å‹çš„æ˜¾ç¤ºåç§°
    model_display_name = case selected_model.to_s
    when 'grok' then 'Grok'
    when 'qwen' then 'Qwen'
    when 'deepseek' then 'DeepSeek'
    when 'gemini' then 'Gemini'
    when 'zhipu' then 'æ™ºè°±'
    when 'doubao' then 'è±†åŒ…'
    else 'Grok'
    end
    
    # ä¼˜åŒ–åçš„èåˆ promptï¼ˆä¸¥æ ¼æ§åˆ¶å†…å®¹è¾¹ç•Œï¼‰
    draft_prompt = <<~PROMPT
      âš ï¸ ã€æ ¸å¿ƒä»»åŠ¡ã€‘
      ä½ ç°åœ¨æ˜¯ä½œè€…æœ¬äººï¼Œè¦å°†è‡ªå·±çš„åˆæ­¥æƒ³æ³•å’Œæ·±åº¦æ€è€ƒèåˆæˆä¸€ç¯‡å®Œæ•´æ–‡ç« ã€‚
      
      ğŸš« ã€ç»å¯¹ç¦æ­¢ã€‘ï¼ˆè¿åä»»ä½•ä¸€æ¡éƒ½ç®—å¤±è´¥ï¼‰
      1. ç¦æ­¢ç¬¬ä¸‰æ–¹è§†è§’ï¼šä¸èƒ½å‡ºç°"æœ‰äººè¯´"ã€"æ ¹æ®XX"ã€"XXæåˆ°"ã€"åˆ†æè®¤ä¸º"ç­‰æ—è§‚è€…è¡¨è¿°
      2. ç¦æ­¢ä»‹ç»æ€§è¯­æ°”ï¼šä¸èƒ½ç”¨"è¿™ä¸ªç³»ç»Ÿ"ã€"è¿™å¥—æ–¹æ³•"ç­‰ä»‹ç»å·²æœ‰äº‹ç‰©çš„å£å»
      3. ç¦æ­¢å¯è§æ‹¼æ¥ï¼šä¸èƒ½è®©è¯»è€…æ„Ÿè§‰æ˜¯ä¸¤æ®µå†…å®¹æ‹¼åœ¨ä¸€èµ·
      4. ç¦æ­¢å¼•ç”¨åŸæ–‡ï¼šä¸èƒ½ç›´æ¥å¼•ç”¨ä¸‹é¢ç´ æçš„åŸè¯ï¼Œè¦å½»åº•æ¶ˆåŒ–åé‡æ–°è¡¨è¾¾
      5. **ç¦æ­¢å†…å®¹æ‰©å±•**ï¼šä¸èƒ½æ·»åŠ ç´ æä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€æ¡ˆä¾‹ã€ç»†èŠ‚ï¼ˆè¿™æ˜¯æœ€ä¸¥é‡çš„è¿è§„ï¼ï¼‰
      6. **ç¦æ­¢è¯¦ç»†å±•å¼€**ï¼šå¦‚æœç´ æåªæ˜¯æåˆ°ï¼Œå°±ä¸è¦è¯¦ç»†æè¿°ï¼ˆå¦‚ï¼šç´ æè¯´"6ä¸ªæ¨¡å‹"ï¼Œä½ ä¸èƒ½å±•å¼€å†™æ¯ä¸ªæ¨¡å‹çš„å†…å®¹ï¼‰
      
      âœ… ã€å¿…é¡»åšåˆ°ã€‘
      1. çº¯ç¬¬ä¸€äººç§°ï¼š"æˆ‘æœ€è¿‘..."ã€"æˆ‘å‘ç°..."ã€"æˆ‘è¯•äº†..."ï¼ˆåƒæ—¥è®°æˆ–åšå®¢ï¼‰
      2. è‡ªç„¶æµç•…ï¼šåƒè‡ªå·±æ€è€ƒåä¸€æ°”å‘µæˆå†™å‡ºæ¥çš„ï¼Œä¸æ˜¯æ•´ç†ä»–äººè§‚ç‚¹
      3. ä¿æŒ #{model_display_name} é£æ ¼ï¼šç›´æ¥ã€æ·±åˆ»ã€æœ‰æ´è§ã€å£è¯­åŒ–ã€ä¸å¥—è¯
      4. é¢å‘è¯»è€…ï¼šåƒè·Ÿæœ‹å‹é¢å¯¹é¢èŠå¤©ï¼Œæœ‰äº’åŠ¨æ„Ÿï¼ˆå¦‚ï¼š"ä½ è¯•è¿‡å—ï¼Ÿ"ã€"å…³é”®æ˜¯..."ï¼‰
      5. **ä¸¥æ ¼æ§åˆ¶é•¿åº¦**ï¼šèåˆç»“æœåº”è¯¥åœ¨ï¼ˆç´ æ1å­—æ•° + ç´ æ2å­—æ•°ï¼‰Ã— 1.5 å€ä»¥å†…ï¼Œç»ä¸è¶…è¿‡
      6. **åªæ•´åˆå·²æœ‰ä¿¡æ¯**ï¼šç´ ææåˆ°ä»€ä¹ˆå°±å†™ä»€ä¹ˆï¼Œä¸æåˆ°çš„ä¸€å¾‹ä¸å†™ï¼Œä¸è„‘è¡¥ï¼Œä¸ä¸¾ä¾‹
      
      âš¡ ã€å…³é”®åŸåˆ™ï¼šèåˆ â‰  æ‰©å±•ã€‘
      - âœ… èåˆ = æŠŠä¸¤æ®µè¯ç”¨ç»Ÿä¸€å£å»é‡æ–°è¯´ä¸€éï¼ˆä¿¡æ¯æ€»é‡ä¸å˜ï¼‰
      - âŒ æ‰©å±• = åŸºäºä¸¤æ®µè¯åˆ›é€ æ–°å†…å®¹ï¼ˆä¸¥é‡è¿è§„ï¼ï¼‰
      - ä¸¾ä¾‹è¯´æ˜ï¼š
        - ç´ æè¯´"æä¾›äº†6ä¸ªæ¨¡å‹" â†’ èåˆï¼š"æˆ‘æäº†6ä¸ªæ¨¡å‹"ï¼ˆâœ… æ­£ç¡®ï¼‰
        - ç´ æè¯´"æä¾›äº†6ä¸ªæ¨¡å‹" â†’ æ‰©å±•ï¼š"ç¬¬ä¸€ä¸ªæ˜¯XXï¼Œç¬¬äºŒä¸ªæ˜¯XX..."ï¼ˆâŒ ä¸¥é‡è¿è§„ï¼ï¼‰
        - ç´ æè¯´"é’ˆå¯¹ä¸åŒåœºæ™¯" â†’ èåˆï¼š"æ¯ä¸ªé’ˆå¯¹ä¸åŒåœºæ™¯"ï¼ˆâœ… æ­£ç¡®ï¼‰
        - ç´ æè¯´"é’ˆå¯¹ä¸åŒåœºæ™¯" â†’ æ‰©å±•ï¼š"æ¯”å¦‚é€šå‹¤æ—¶ã€æ—©ä¸Šé†’æ¥æ—¶..."ï¼ˆâŒ ä¸¥é‡è¿è§„ï¼ï¼‰
      
      ğŸ“ ã€æ ¼å¼è¦æ±‚ - å¿…é¡»ä½¿ç”¨ Markdownã€‘
      ä½ **å¿…é¡»**ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼ŒåŒ…æ‹¬ï¼š
      - **æ ‡é¢˜ç»“æ„**ï¼šä½¿ç”¨ ## äºŒçº§æ ‡é¢˜ å’Œ ### ä¸‰çº§æ ‡é¢˜æ¥ç»„ç»‡å†…å®¹ï¼ˆä¸è¦ä½¿ç”¨ # ä¸€çº§æ ‡é¢˜ï¼‰
      - **é‡ç‚¹å¼ºè°ƒ**ï¼šç”¨ **åŠ ç²—** æ ‡è®°å…³é”®è¯å’Œé‡è¦è§‚ç‚¹
      - **åˆ—è¡¨**ï¼šç”¨ - æˆ–æ•°å­—åˆ—è¡¨æ¥å‘ˆç°è¦ç‚¹
      - **æ®µè½åˆ†éš”**ï¼šæ®µè½ä¹‹é—´ç©ºä¸€è¡Œ
      - **é€»è¾‘æ¸…æ™°**ï¼šç”¨æ ‡é¢˜å’Œåˆ—è¡¨è®©æ–‡ç« ç»“æ„ä¸€ç›®äº†ç„¶
      
      ç¤ºä¾‹æ ¼å¼ï¼š
      ```
      ## æˆ‘çš„å‘ç°
      
      æœ€è¿‘æˆ‘åœ¨æ€è€ƒä¸€ä¸ªé—®é¢˜...
      
      ### å…³é”®è¦ç‚¹
      
      - **ç¬¬ä¸€ç‚¹**ï¼šé‡è¦å†…å®¹
      - **ç¬¬äºŒç‚¹**ï¼šå¦ä¸€ä¸ªè¦ç‚¹
      
      ### å…·ä½“å®è·µ
      
      æˆ‘å°è¯•äº†ä»¥ä¸‹æ–¹æ³•ï¼š
      
      1. é¦–å…ˆåšäº†...
      2. ç„¶åå‘ç°...
      ```
      
      ğŸ“ ã€å†™ä½œæŒ‡å—ã€‘
      - è§’è‰²ï¼šä½ å°±æ˜¯ä½œè€…æœ¬äººï¼Œæ­£åœ¨å†™ä¸€ç¯‡ä¸ªäººåšå®¢/å…¬ä¼—å·æ–‡ç« 
      - ç´ æç”¨æ³•ï¼šä¸‹é¢çš„å†…å®¹æ˜¯ä½ çš„ç¬”è®°å’Œè‰ç¨¿ï¼Œç°åœ¨è¦æ•´ç†æˆæ­£å¼æ–‡ç« 
      - **å†…å®¹å–èˆ**ï¼šåªèƒ½åˆ å‡ã€é‡ç»„ã€æ¢è¯´æ³•ï¼Œç»ä¸èƒ½æ‰©å±•ã€ä¸¾ä¾‹ã€è¯¦è¿°
      - è¾“å‡ºè¦æ±‚ï¼šç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„æ–‡ç« æ­£æ–‡ï¼Œä¸è¦åŠ æ–‡ç« æ€»æ ‡é¢˜ã€è§£é‡Šæˆ–ä»»ä½•å¤šä½™å†…å®¹
      - **é•¿åº¦æ§åˆ¶**ï¼šå†™å®Œç«‹å³åœæ­¢ï¼Œä¸è¦ä¸ºäº†å‡‘å­—æ•°è€Œå•°å—¦
      
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      ã€ç´ æ1ï¼šåˆæ­¥æƒ³æ³•ã€‘
      #{article.transcript}
      
      ã€ç´ æ2ï¼šæ·±åº¦æ€è€ƒã€‘
      #{selected_brainstorm}
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      
      ç°åœ¨ï¼Œä»¥ç¬¬ä¸€äººç§°ã€ä½¿ç”¨ Markdown æ ¼å¼å†™å‡ºèåˆåçš„å®Œæ•´æ–‡ç« ï¼ˆç›´æ¥å¼€å§‹ï¼Œä¸è¦å‰è¨€ï¼‰ï¼š
      
      âš ï¸ ã€æœ€ç»ˆæé†’ã€‘
      - åªæ•´åˆç´ æä¸­çš„ä¿¡æ¯ï¼Œä¸æ‰©å±•ï¼Œä¸è¯¦è¿°ï¼Œä¸ä¸¾ä¾‹
      - å­—æ•°æ§åˆ¶åœ¨ç´ ææ€»å­—æ•°çš„1.5å€ä»¥å†…
      - å†™å®Œç«‹å³åœæ­¢ï¼Œä¸è¦ä¸ºäº†è¾¾åˆ°æŸä¸ªå­—æ•°è€Œç»§ç»­
      - **å¿…é¡»ä½¿ç”¨ Markdown æ ¼å¼**ï¼šæ ‡é¢˜ã€åŠ ç²—ã€åˆ—è¡¨ç­‰
    PROMPT
    
    llm_config = get_llm_config(selected_model)
    
    # CRITICAL: Draft generation needs longer timeout due to long prompt and content fusion
    # - Long prompt: ~180 lines of detailed instructions
    # - Content fusion: transcript + brainstorm content (can be 2000+ characters)
    # - Default 120s often causes timeout, especially for slower models like Zhipu
    # Also increase max_tokens to allow longer output (fusion of multiple contents)
    llm_config_with_timeout = llm_config.merge(timeout: 240, max_tokens: 8000)
    
    LlmStreamJob.perform_later(
      stream_name: "#{@stream_name}_draft",
      prompt: draft_prompt,
      llm_config: llm_config_with_timeout,
      article_id: article.id,
      provider: 'draft',
      streaming: false  # ä½¿ç”¨éæµå¼è¾“å‡ºï¼Œç­‰å¾…å®Œæ•´å†…å®¹ç”Ÿæˆåä¸€æ¬¡æ€§æ˜¾ç¤º
    )
  end
  
  private
  
  def get_llm_config(provider)
    case provider.to_s
    when 'qwen'
      {
        base_url: ENV.fetch('QWEN_BASE_URL_OPTIONAL'),
        api_key: ENV.fetch('QWEN_API_KEY_OPTIONAL'),
        model: ENV.fetch('QWEN_MODEL_OPTIONAL')
      }
    when 'deepseek'
      {
        base_url: ENV.fetch('DEEPSEEK_BASE_URL_OPTIONAL'),
        api_key: ENV.fetch('DEEPSEEK_API_KEY_OPTIONAL'),
        model: ENV.fetch('DEEPSEEK_MODEL_OPTIONAL')
      }
    when 'gemini'
      {
        base_url: ENV.fetch('GEMINI_BASE_URL_OPTIONAL'),
        api_key: ENV.fetch('GEMINI_API_KEY_OPTIONAL'),
        model: ENV.fetch('GEMINI_MODEL_OPTIONAL')
      }
    when 'zhipu'
      {
        base_url: ENV.fetch('ZHIPU_BASE_URL_OPTIONAL'),
        api_key: ENV.fetch('ZHIPU_API_KEY_OPTIONAL'),
        model: ENV.fetch('ZHIPU_MODEL_OPTIONAL')
      }
    when 'chatgpt'
      {
        base_url: ENV.fetch('CHATGPT_BASE_URL_OPTIONAL'),
        api_key: ENV.fetch('CHATGPT_API_KEY_OPTIONAL'),
        model: ENV.fetch('CHATGPT_MODEL_OPTIONAL')
      }
    when 'doubao'
      {
        base_url: ENV.fetch('DOUBAO_BASE_URL_OPTIONAL'),
        api_key: ENV.fetch('DOUBAO_API_KEY_OPTIONAL'),
        model: ENV.fetch('DOUBAO_MODEL_OPTIONAL')
      }
    when 'grok'
      {
        base_url: ENV.fetch('LLM_BASE_URL'),
        api_key: ENV.fetch('LLM_API_KEY'),
        model: ENV.fetch('LLM_MODEL')
      }
    else
      # Default to Grok
      {
        base_url: ENV.fetch('LLM_BASE_URL'),
        api_key: ENV.fetch('LLM_API_KEY'),
        model: ENV.fetch('LLM_MODEL')
      }
    end
  end

  
  # def current_user
  #   @current_user ||= connection.current_user
  # end
end
